[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "",
    "text": "The data analyzed in this report come from the Diabetes Health Indicators dataset\n(diabetes_binary_health_indicators_BRFSS2015). Each row corresponds to a survey respondent and includes a diabetes status indicator (Diabetes_012), along with a variety of health and lifestyle indicators such as blood pressure, BMI, physical activity, smoking status, general health, and socio-demographic variables.\nIn this version of the dataset, the variable:\n\nDiabetes_012 is coded as:\n\n0 = no diabetes\n1 = prediabetes\n2 = diabetes\n\n\nOur goals in this EDA are to:\n\nDescribe the variables that will be used in the subsequent modeling.\nUnderstand the distribution of the response variable (Diabetes_012).\nExplore how key predictors relate to diabetes status.\nIdentify potential data quality issues (missing values, unusual distributions).\nBuild intuition that will guide model selection in the Modeling document.\n\nThe ultimate goal is to build a predictive model related to diabetes status, which will be developed in the modeling page/report."
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "",
    "text": "The data analyzed in this report come from the Diabetes Health Indicators dataset\n(diabetes_binary_health_indicators_BRFSS2015). Each row corresponds to a survey respondent and includes a diabetes status indicator (Diabetes_012), along with a variety of health and lifestyle indicators such as blood pressure, BMI, physical activity, smoking status, general health, and socio-demographic variables.\nIn this version of the dataset, the variable:\n\nDiabetes_012 is coded as:\n\n0 = no diabetes\n1 = prediabetes\n2 = diabetes\n\n\nOur goals in this EDA are to:\n\nDescribe the variables that will be used in the subsequent modeling.\nUnderstand the distribution of the response variable (Diabetes_012).\nExplore how key predictors relate to diabetes status.\nIdentify potential data quality issues (missing values, unusual distributions).\nBuild intuition that will guide model selection in the Modeling document.\n\nThe ultimate goal is to build a predictive model related to diabetes status, which will be developed in the modeling page/report."
  },
  {
    "objectID": "EDA.html#load-packages",
    "href": "EDA.html#load-packages",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Load Packages",
    "text": "Load Packages\nWe begin by loading the R packages that will be used throughout the analysis.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\nlibrary(skimr)\nlibrary(GGally)\n\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "EDA.html#read-and-prepare-the-data",
    "href": "EDA.html#read-and-prepare-the-data",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Read and Prepare the Data",
    "text": "Read and Prepare the Data\nNext, we read the dataset from the data/ folder and perform some initial cleaning steps (I know from Kaggle this is the cleaned sample). We keep a numeric version of the diabetes indicator for correlations, create a factor version for plots/modeling, recode Sex as a labeled factor, and provide more interpretable labels for GenHlth and Age.\n\ndiabetes_raw &lt;- readr::read_csv(\n  \"data/diabetes_binary_health_indicators_BRFSS2015.csv\"\n)\n\nage_labels &lt;- c(\n  \"18–24\", \"25–29\", \"30–34\", \"35–39\",\n  \"40–44\", \"45–49\", \"50–54\", \"55–59\",\n  \"60–64\", \"65–69\", \"70–74\", \"75–79\", \"80+\"\n)\n\ndiabetes &lt;- diabetes_raw |&gt;\n  mutate(\n    # numeric copy of the diabetes indicator\n    Diabetes_num = Diabetes_012,\n    # factor version for classification / plots\n    Diabetes_012 = factor(\n      Diabetes_012,\n      levels = c(0, 1, 2),\n      labels = c(\"No_diabetes\", \"Prediabetes\", \"Diabetes\")\n    ),\n    Sex = factor(\n      Sex,\n      levels = c(0, 1),\n      labels = c(\"Female\", \"Male\")\n    ),\n    GenHlth = factor(\n      GenHlth,\n      levels = 1:5,\n      labels = c(\"Excellent\", \"Very_good\", \"Good\", \"Fair\", \"Poor\"),\n      ordered = TRUE\n    ),\n    Age_num = Age,\n    Age = factor(\n      Age,\n      levels = 1:13,\n      labels = age_labels,\n      ordered = TRUE\n    )\n  )\n\ndiabetes\n\n# A tibble: 253,680 × 24\n   Diabetes_012 HighBP HighChol CholCheck   BMI Smoker Stroke\n   &lt;fct&gt;         &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 No_diabetes       1        1         1    40      1      0\n 2 No_diabetes       0        0         0    25      1      0\n 3 No_diabetes       1        1         1    28      0      0\n 4 No_diabetes       1        0         1    27      0      0\n 5 No_diabetes       1        1         1    24      0      0\n 6 No_diabetes       1        1         1    25      1      0\n 7 No_diabetes       1        0         1    30      1      0\n 8 No_diabetes       1        1         1    25      1      0\n 9 Diabetes          1        1         1    30      1      0\n10 No_diabetes       0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 17 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;ord&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;fct&gt;, Age &lt;ord&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;,\n#   Diabetes_num &lt;dbl&gt;, Age_num &lt;dbl&gt;"
  },
  {
    "objectID": "EDA.html#basic-data-overview",
    "href": "EDA.html#basic-data-overview",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Basic Data Overview",
    "text": "Basic Data Overview\nWe first report the number of observations and variables in the cleaned dataset.\n\nn_obs  &lt;- nrow(diabetes)\nn_vars &lt;- ncol(diabetes)\n\ntibble(\n  n_observations = n_obs,\n  n_variables    = n_vars\n)\n\n# A tibble: 1 × 2\n  n_observations n_variables\n           &lt;int&gt;       &lt;int&gt;\n1         253680          24\n\n\nWe then use skimr::skim() to obtain a high-level summary of the distributions and types of all variables.\n\nskimr::skim(diabetes)\n\n\nData summary\n\n\nName\ndiabetes\n\n\nNumber of rows\n253680\n\n\nNumber of columns\n24\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n20\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nDiabetes_012\n0\n1\nFALSE\n3\nNo_: 213703, Dia: 35346, Pre: 4631\n\n\nGenHlth\n0\n1\nTRUE\n5\nVer: 89084, Goo: 75646, Exc: 45299, Fai: 31570\n\n\nSex\n0\n1\nFALSE\n2\nFem: 141974, Mal: 111706\n\n\nAge\n0\n1\nTRUE\n13\n60–: 33244, 65–: 32194, 55–: 30832, 50–: 26314\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHighBP\n0\n1\n0.43\n0.49\n0\n0\n0\n1\n1\n▇▁▁▁▆\n\n\nHighChol\n0\n1\n0.42\n0.49\n0\n0\n0\n1\n1\n▇▁▁▁▆\n\n\nCholCheck\n0\n1\n0.96\n0.19\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nBMI\n0\n1\n28.38\n6.61\n12\n24\n27\n31\n98\n▇▅▁▁▁\n\n\nSmoker\n0\n1\n0.44\n0.50\n0\n0\n0\n1\n1\n▇▁▁▁▆\n\n\nStroke\n0\n1\n0.04\n0.20\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nHeartDiseaseorAttack\n0\n1\n0.09\n0.29\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nPhysActivity\n0\n1\n0.76\n0.43\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nFruits\n0\n1\n0.63\n0.48\n0\n0\n1\n1\n1\n▅▁▁▁▇\n\n\nVeggies\n0\n1\n0.81\n0.39\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\nHvyAlcoholConsump\n0\n1\n0.06\n0.23\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nAnyHealthcare\n0\n1\n0.95\n0.22\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\nNoDocbcCost\n0\n1\n0.08\n0.28\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nMentHlth\n0\n1\n3.18\n7.41\n0\n0\n0\n2\n30\n▇▁▁▁▁\n\n\nPhysHlth\n0\n1\n4.24\n8.72\n0\n0\n0\n3\n30\n▇▁▁▁▁\n\n\nDiffWalk\n0\n1\n0.17\n0.37\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nEducation\n0\n1\n5.05\n0.99\n1\n4\n5\n6\n6\n▁▁▅▅▇\n\n\nIncome\n0\n1\n6.05\n2.07\n1\n5\n7\n8\n8\n▁▁▃▂▇\n\n\nDiabetes_num\n0\n1\n0.30\n0.70\n0\n0\n0\n0\n2\n▇▁▁▁▁\n\n\nAge_num\n0\n1\n8.03\n3.05\n1\n6\n8\n10\n13\n▂▃▇▇▆"
  },
  {
    "objectID": "EDA.html#variables-of-interest",
    "href": "EDA.html#variables-of-interest",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Variables of Interest",
    "text": "Variables of Interest\nFor this project, we focus on a subset of predictors that are both interpretable and likely to be informative for predicting diabetes status. Here we select these variables and inspect their structure.\n\nvars_of_interest &lt;- diabetes |&gt;\n  select(\n    Diabetes_012,\n    HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,\n    HeartDiseaseorAttack, PhysActivity, Fruits, Veggies,\n    HvyAlcoholConsump, AnyHealthcare, NoDocbcCost,\n    GenHlth, MentHlth, PhysHlth, DiffWalk,\n    Sex, Age, Age_num, Education, Income,\n    Diabetes_num\n  )\n\nglimpse(vars_of_interest)\n\nRows: 253,680\nColumns: 24\n$ Diabetes_012         &lt;fct&gt; No_diabetes, No_diabetes, No_diabetes, No_diabete…\n$ HighBP               &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1…\n$ HighChol             &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1…\n$ CholCheck            &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ BMI                  &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34, 2…\n$ Smoker               &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0…\n$ Stroke               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ HeartDiseaseorAttack &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ PhysActivity         &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1…\n$ Fruits               &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1…\n$ Veggies              &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1…\n$ HvyAlcoholConsump    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ AnyHealthcare        &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ NoDocbcCost          &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ GenHlth              &lt;ord&gt; Poor, Good, Poor, Very_good, Very_good, Very_good…\n$ MentHlth             &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30, …\n$ PhysHlth             &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0, 2…\n$ DiffWalk             &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0…\n$ Sex                  &lt;fct&gt; Female, Female, Female, Female, Female, Male, Fem…\n$ Age                  &lt;ord&gt; 60–64, 50–54, 60–64, 70–74, 70–74, 65–69, 60–64, …\n$ Age_num              &lt;dbl&gt; 9, 7, 9, 11, 11, 10, 9, 11, 9, 8, 13, 10, 7, 11, …\n$ Education            &lt;dbl&gt; 4, 6, 4, 3, 5, 6, 6, 4, 5, 4, 6, 5, 5, 4, 6, 6, 4…\n$ Income               &lt;dbl&gt; 3, 1, 8, 6, 4, 8, 7, 4, 1, 3, 8, 1, 7, 6, 2, 8, 3…\n$ Diabetes_num         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0…"
  },
  {
    "objectID": "EDA.html#missing-data",
    "href": "EDA.html#missing-data",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Missing Data",
    "text": "Missing Data\nBefore proceeding with the analysis, we investigate the extent of missing data for each selected variable. First, we summarize the number and proportion of missing values by variable.\n\nmissing_summary &lt;- vars_of_interest |&gt;\n  select(-Diabetes_num, -Age_num) |&gt;\n  summarise(across(everything(), ~ sum(is.na(.)))) |&gt;\n  pivot_longer(everything(),\n               names_to = \"variable\",\n               values_to = \"n_missing\") |&gt;\n  mutate(prop_missing = n_missing / n_obs)\n\nmissing_summary |&gt;\n  arrange(desc(n_missing)) |&gt; \n  head(10)\n\n# A tibble: 10 × 3\n   variable             n_missing prop_missing\n   &lt;chr&gt;                    &lt;int&gt;        &lt;dbl&gt;\n 1 Diabetes_012                 0            0\n 2 HighBP                       0            0\n 3 HighChol                     0            0\n 4 CholCheck                    0            0\n 5 BMI                          0            0\n 6 Smoker                       0            0\n 7 Stroke                       0            0\n 8 HeartDiseaseorAttack         0            0\n 9 PhysActivity                 0            0\n10 Fruits                       0            0\n\n\nWe then visualize the proportion of missing values among variables that have at least one missing observation. If there are no missing values, we simply print a message indicating that the data are complete.\n\nif (any(missing_summary$n_missing &gt; 0)) {\n  missing_summary |&gt;\n    filter(n_missing &gt; 0) |&gt;\n    ggplot(aes(x = reorder(variable, prop_missing),\n               y = prop_missing)) +\n    geom_col() +\n    coord_flip() +\n    scale_y_continuous(labels = scales::percent_format()) +\n    labs(\n      x = NULL,\n      y = \"Proportion Missing\",\n      title = \"Proportion of Missing Values by Variable\"\n    )\n} else {\n  tibble(msg = \"No missing values were found in the selected variables.\") |&gt;\n    knitr::kable()\n}\n\n\n\n\nmsg\n\n\n\n\nNo missing values were found in the selected variables.\n\n\n\n\n\nThis is the cleaned dataset explained in the Kaggle, so I was not expecting any missing value."
  },
  {
    "objectID": "EDA.html#distribution-of-the-response-diabetes_012",
    "href": "EDA.html#distribution-of-the-response-diabetes_012",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Distribution of the Response: Diabetes_012",
    "text": "Distribution of the Response: Diabetes_012\nWe next examine the distribution of the diabetes status indicator to understand class balance across the three categories.\n\nresp_counts &lt;- vars_of_interest |&gt;\n  count(Diabetes_012) |&gt;\n  mutate(prop = n / sum(n))\n\nresp_counts\n\n# A tibble: 3 × 3\n  Diabetes_012      n   prop\n  &lt;fct&gt;         &lt;int&gt;  &lt;dbl&gt;\n1 No_diabetes  213703 0.842 \n2 Prediabetes    4631 0.0183\n3 Diabetes      35346 0.139 \n\n\nWe visualize these proportions with a bar plot.\n\nresp_counts |&gt;\n  ggplot(aes(x = Diabetes_012, y = prop, fill = Diabetes_012)) +\n  geom_col(show.legend = FALSE) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    x = \"Diabetes Status\",\n    y = \"Proportion of Respondents\",\n    title = \"Prevalence of Diabetes Status in the Sample\"\n  )\n\n\n\n\n\n\n\n\nThe dataset is imbalanced, with a smaller proportion of respondents labeled as diabetes compared to those without diabetes. Prediabetes appears as an intermediate category. This imbalance will be important to considerwhen evaluating models. This was mentioned in the Kaggle website"
  },
  {
    "objectID": "EDA.html#univariate-distributions-of-key-numeric-predictors",
    "href": "EDA.html#univariate-distributions-of-key-numeric-predictors",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Univariate Distributions of Key Numeric Predictors",
    "text": "Univariate Distributions of Key Numeric Predictors\nWe begin by studying the distributions of some important numeric variables: BMI, days of poor mental health, and days of poor physical health.\n\nvars_of_interest |&gt;\n  select(BMI, MentHlth, PhysHlth) |&gt;\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"value\") |&gt;\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~ variable, scales = \"free_x\") +\n  labs(\n    x = NULL,\n    y = \"Count\",\n    title = \"Distributions of Selected Numeric Predictors\"\n  )\n\n\n\n\n\n\n\n\nBMI usually right-skewed, with most values in the 20–40 range. Mental and physical health days are often concentrated at 0, with a long right tail for respondents reporting many days of poor health."
  },
  {
    "objectID": "EDA.html#univariate-distributions-of-key-binarycategorical-predictors",
    "href": "EDA.html#univariate-distributions-of-key-binarycategorical-predictors",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Univariate Distributions of Key Binary/Categorical Predictors",
    "text": "Univariate Distributions of Key Binary/Categorical Predictors\nMany predictors in this dataset are Dummy or 0/1 indicators. Here I examine the marginal distributions for a few key binary variables, followed by a separate summary of the sex variable.\n\ncat_vars &lt;- vars_of_interest |&gt;\n  select(HighBP, HighChol, Smoker, PhysActivity,\n         Fruits, Veggies, DiffWalk)\n\ncat_vars |&gt;\n  pivot_longer(everything(),\n               names_to = \"variable\",\n               values_to = \"value\") |&gt;\n  mutate(value = factor(value)) |&gt;\n  group_by(variable, value) |&gt;\n  summarise(n = n(), .groups = \"drop\") |&gt;\n  group_by(variable) |&gt;\n  mutate(prop = n / sum(n)) |&gt;\n  ggplot(aes(x = value, y = prop, fill = value)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ variable, scales = \"free_x\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    x = NULL,\n    y = \"Proportion\",\n    title = \"Distributions of Selected Binary Predictors\"\n  )\n\n\n\n\n\n\n\n\n\nvars_of_interest |&gt;\n  count(Sex) |&gt;\n  mutate(prop = n / sum(n)) |&gt;\n  ggplot(aes(x = Sex, y = prop, fill = Sex)) +\n  geom_col(show.legend = FALSE) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    x = \"Sex\",\n    y = \"Proportion\",\n    title = \"Distribution of Sex\"\n  )\n\n\n\n\n\n\n\n\nThese plots show the prevalence of high blood pressure, high cholesterol, smoking, physical activity, difficulty walking, and sex in the sample."
  },
  {
    "objectID": "EDA.html#numeric-predictors-vs.-diabetes-status",
    "href": "EDA.html#numeric-predictors-vs.-diabetes-status",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Numeric Predictors vs. Diabetes Status",
    "text": "Numeric Predictors vs. Diabetes Status\nWe now turn to bivariate relationships. First, we compare BMI, mental health days, and physical health days across diabetes status groups using boxplots.\n\nvars_of_interest |&gt;\n  select(Diabetes_012, BMI, MentHlth, PhysHlth) |&gt;\n  pivot_longer(cols = c(BMI, MentHlth, PhysHlth),\n               names_to = \"variable\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(x = Diabetes_012, y = value, fill = Diabetes_012)) +\n  geom_boxplot(outlier.alpha = 0.2, show.legend = FALSE) +\n  facet_wrap(~ variable, scales = \"free_y\") +\n  labs(\n    x = \"Diabetes Status\",\n    y = NULL,\n    title = \"Numeric Predictors by Diabetes Status\"\n  )\n\n\n\n\n\n\n\n\nRespondents with diabetes tend to have higher BMI and more days of poor physical health. Differences in mental health days may also be present but could be less pronounced."
  },
  {
    "objectID": "EDA.html#binary-predictors-vs.-diabetes-status",
    "href": "EDA.html#binary-predictors-vs.-diabetes-status",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Binary Predictors vs. Diabetes Status",
    "text": "Binary Predictors vs. Diabetes Status\nFor binary predictors, we compare the proportion of “1” (Yes) within each diabetes group.\n\nbinary_vars &lt;- vars_of_interest |&gt;\n  select(Diabetes_012,\n         HighBP, HighChol, Smoker, PhysActivity,\n         Fruits, Veggies, DiffWalk)\n\nbinary_long &lt;- binary_vars |&gt;\n  pivot_longer(\n    cols = -Diabetes_012,\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) |&gt;\n  mutate(value = factor(value))\n\nbinary_long |&gt;\n  group_by(Diabetes_012, variable) |&gt;\n  summarise(prop_yes = mean(value == \"1\"), .groups = \"drop\") |&gt;\n  ggplot(aes(x = variable, y = prop_yes,\n             fill = Diabetes_012)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    x = NULL,\n    y = \"Proportion with value = 1\",\n    fill = \"Diabetes status\",\n    title = \"Proportion of 'Yes' for Binary Predictors by Diabetes Status\"\n  )\n\n\n\n\n\n\n\n\nIndividuals with diabetes are more likely to report high blood pressure, high cholesterol, difficulty walking, and lower levels of physical activity. These patterns support the inclusion of these predictors in our models."
  },
  {
    "objectID": "EDA.html#ordinal-predictors-vs.-diabetes-status",
    "href": "EDA.html#ordinal-predictors-vs.-diabetes-status",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Ordinal Predictors vs. Diabetes Status",
    "text": "Ordinal Predictors vs. Diabetes Status\nWe now investigate how self-reported general health (GenHlth), age category, education, and income differ by diabetes status.\n\nordinal_vars &lt;- vars_of_interest |&gt;\n  select(Diabetes_012, GenHlth, Age, Education, Income) |&gt;\n  # make all ordinal predictors character so pivot_longer is happy\n  mutate(across(c(GenHlth, Age, Education, Income), as.character))\n\nordinal_long &lt;- ordinal_vars |&gt;\n  pivot_longer(\n    cols = -Diabetes_012,\n    names_to = \"variable\",\n    values_to = \"value\"\n  )\n\nordinal_long |&gt;\n  group_by(Diabetes_012, variable, value) |&gt;\n  summarise(n = n(), .groups = \"drop\") |&gt;\n  group_by(Diabetes_012, variable) |&gt;\n  mutate(prop = n / sum(n)) |&gt;\n  ggplot(aes(x = value, y = prop,\n             fill = Diabetes_012)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ variable, scales = \"free_x\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    x = \"Category\",\n    y = \"Proportion\",\n    fill = \"Diabetes status\",\n    title = \"Ordinal Predictors by Diabetes Status\"\n  )\n\n\n\n\n\n\n\n\nDiabetes tends to be more prevalent in older age categories, among respondents with worse self-reported general health, and potentially among those with lower income and education levels. These patterns suggest that demographic and socio-economic variables may add predictive power."
  },
  {
    "objectID": "EDA.html#correlation-among-numeric-predictors",
    "href": "EDA.html#correlation-among-numeric-predictors",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Correlation Among Numeric Predictors",
    "text": "Correlation Among Numeric Predictors\nFinally, we examine the correlation structure among numeric predictors and the diabetes indicator (using the numeric version Diabetes_num and Age_num).\n\nnumeric_for_cor &lt;- vars_of_interest |&gt;\n  select(Diabetes_num, BMI, MentHlth, PhysHlth, Age_num, Education, Income)\n\ncor_mat &lt;- cor(numeric_for_cor, use = \"pairwise.complete.obs\")\n\nround(cor_mat, 2)\n\n             Diabetes_num   BMI MentHlth PhysHlth Age_num Education Income\nDiabetes_num         1.00  0.22     0.07     0.18    0.19     -0.13  -0.17\nBMI                  0.22  1.00     0.09     0.12   -0.04     -0.10  -0.10\nMentHlth             0.07  0.09     1.00     0.35   -0.09     -0.10  -0.21\nPhysHlth             0.18  0.12     0.35     1.00    0.10     -0.16  -0.27\nAge_num              0.19 -0.04    -0.09     0.10    1.00     -0.10  -0.13\nEducation           -0.13 -0.10    -0.10    -0.16   -0.10      1.00   0.45\nIncome              -0.17 -0.10    -0.21    -0.27   -0.13      0.45   1.00\n\n\nWe also visualize this correlation matrix using GGally::ggcorr().\n\nggcorr(\n  numeric_for_cor,\n  label = TRUE,\n  label_round = 2,\n  label_size = 3\n) +\n  labs(\n    title = \"Correlation Matrix for Selected Numeric Predictors\"\n  )\n\n\n\n\n\n\n\n\nThe correlation matrix highlights the relationships among BMI, age, health days, and diabetes status. While no single predictor is perfectly correlated with diabetes, several variables show moderate associations that justify their inclusion in the modeling step."
  },
  {
    "objectID": "EDA.html#summary-and-next-steps",
    "href": "EDA.html#summary-and-next-steps",
    "title": "Diabetes Health Indicators – Exploratory Data Analysis",
    "section": "Summary and Next Steps",
    "text": "Summary and Next Steps\nIn this EDA, we:\n\nDescribed the structure of the Diabetes Health Indicators dataset.\nExplored the marginal distribution of the multi-level diabetes indicator (Diabetes_012).\nExamined key numeric, binary, and ordinal predictors and their relationships with diabetes status.\nIdentified variables that appear strongly associated with diabetes, including high blood pressure, high cholesterol, BMI, physical activity, difficulty walking, and general health, as well as age and income.\n\nThese insights will guide the construction of predictive models in the next stage, where we will fit and compare a classification tree and a random forest using the tidymodels framework, with model performance evaluated via log-loss on a held-out test set.\nClick here for the Modeling Page"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "",
    "text": "In this report we build and compare predictive models for diabetes using the Diabetes Health Indicators dataset (diabetes_binary_health_indicators_BRFSS2015). The original outcome variable, Diabetes_012, has three categories:\n\n0 = no diabetes\n\n1 = prediabetes\n\n2 = diabetes\n\nFor this project we follow the course instructions and work with a binary response. We define a new variable, Diabetes_binary, that indicates whether a respondent has diabetes (1) or not (0):\n\nDiabetes_binary = 1 if Diabetes_012 == 2 (diabetes)\n\nDiabetes_binary = 0 otherwise (no diabetes or prediabetes)\n\nOur goals in this document are to:\n\nCreate a training/test split of the data.\nSpecify a modeling recipe based on insights from the EDA.\nFit and tune a classification tree model.\nFit and tune a random forest model.\nUse log-loss with 5-fold cross-validation to select the best model in each family.\nCompare the final tuned models on the test set and select a winner.\n\nWe use the tidymodels framework to keep preprocessing, resampling, tuning, and evaluation organized and reproducible."
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "",
    "text": "In this report we build and compare predictive models for diabetes using the Diabetes Health Indicators dataset (diabetes_binary_health_indicators_BRFSS2015). The original outcome variable, Diabetes_012, has three categories:\n\n0 = no diabetes\n\n1 = prediabetes\n\n2 = diabetes\n\nFor this project we follow the course instructions and work with a binary response. We define a new variable, Diabetes_binary, that indicates whether a respondent has diabetes (1) or not (0):\n\nDiabetes_binary = 1 if Diabetes_012 == 2 (diabetes)\n\nDiabetes_binary = 0 otherwise (no diabetes or prediabetes)\n\nOur goals in this document are to:\n\nCreate a training/test split of the data.\nSpecify a modeling recipe based on insights from the EDA.\nFit and tune a classification tree model.\nFit and tune a random forest model.\nUse log-loss with 5-fold cross-validation to select the best model in each family.\nCompare the final tuned models on the test set and select a winner.\n\nWe use the tidymodels framework to keep preprocessing, resampling, tuning, and evaluation organized and reproducible."
  },
  {
    "objectID": "Modeling.html#load-packages",
    "href": "Modeling.html#load-packages",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "Load Packages",
    "text": "Load Packages\nWe begin by loading the packages needed for modeling.\n#| label: setup-packages\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\nlibrary(tidymodels)\n\ntidymodels_prefer()\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Modeling.html#read-and-prepare-the-data",
    "href": "Modeling.html#read-and-prepare-the-data",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "Read and Prepare the Data",
    "text": "Read and Prepare the Data\nHere we read the same dataset used in the EDA and perform minimal cleaning so that the modeling file is self-contained. We:\n\nKeep a numeric copy of Diabetes_012.\nCreate a binary outcome Diabetes_binary (No_diabetes vs Diabetes).\nRecode Sex as a factor with labels.\nProvide interpretable labels for GenHlth and Age.\n\n#| label: read-and-clean\n#| message: false\n#| warning: false\n\ndiabetes_raw &lt;- readr::read_csv(\n  \"data/diabetes_binary_health_indicators_BRFSS2015.csv\"\n)\n\nage_labels &lt;- c(\n  \"18–24\", \"25–29\", \"30–34\", \"35–39\",\n  \"40–44\", \"45–49\", \"50–54\", \"55–59\",\n  \"60–64\", \"65–69\", \"70–74\", \"75–79\", \"80+\"\n)\n\ndiabetes &lt;- diabetes_raw |&gt;\n  mutate(\n    Diabetes_num = Diabetes_012,\n    Diabetes_012 = factor(\n      Diabetes_012,\n      levels = c(0, 1, 2),\n      labels = c(\"No_diabetes\", \"Prediabetes\", \"Diabetes\")\n    ),\n    # Binary response for modeling\n    Diabetes_binary = if_else(Diabetes_012 == \"Diabetes\", 1, 0),\n    Diabetes_binary = factor(\n      Diabetes_binary,\n      levels = c(0, 1),\n      labels = c(\"No_diabetes\", \"Diabetes\")\n    ),\n    Sex = factor(\n      Sex,\n      levels = c(0, 1),\n      labels = c(\"Female\", \"Male\")\n    ),\n    GenHlth = factor(\n      GenHlth,\n      levels = 1:5,\n      labels = c(\"Excellent\", \"Very_good\", \"Good\", \"Fair\", \"Poor\"),\n      ordered = TRUE\n    ),\n    Age_num = Age,\n    Age = factor(\n      Age,\n      levels = 1:13,\n      labels = age_labels,\n      ordered = TRUE\n    )\n  )\n\ndiabetes |&gt; \n  count(Diabetes_binary) |&gt; \n  mutate(prop = n / sum(n))\nThe binary outcome is imbalanced, with the “Diabetes” class representing a smaller proportion of observations. This will influence how we interpret log-loss and other metrics."
  },
  {
    "objectID": "Modeling.html#traintest-split",
    "href": "Modeling.html#traintest-split",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "Train/Test Split",
    "text": "Train/Test Split\nWe now split the data into a training set (70%) and a test set (30%), stratifying on the binary outcome to preserve class proportions in each partition.\n#| label: split-data\n#| message: false\n\nset.seed(2025)\n\ndata_split &lt;- initial_split(\n  diabetes,\n  prop   = 0.7,\n  strata = Diabetes_binary\n)\n\ndata_train &lt;- training(data_split)\ndata_test  &lt;- testing(data_split)\n\ndata_split"
  },
  {
    "objectID": "Modeling.html#modeling-strategy-and-predictors",
    "href": "Modeling.html#modeling-strategy-and-predictors",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "Modeling Strategy and Predictors",
    "text": "Modeling Strategy and Predictors\nGuided by the EDA, we choose a set of predictors that showed meaningful associations with diabetes status:\n\nHighBP, HighChol, BMI, Smoker\n\nPhysActivity, GenHlth, DiffWalk\n\nAge, Sex, Income\n\nWe build a recipe that:\n\nSpecifies the outcome and predictors.\nHandles missing values for numeric predictors via median imputation.\nHandles missing values for nominal predictors via mode imputation.\nCreates dummy variables for nominal predictors.\n\n#| label: recipe\n#| message: false\n\ndiabetes_rec &lt;- recipe(\n  Diabetes_binary ~ HighBP + HighChol + BMI + Smoker +\n    PhysActivity + GenHlth + DiffWalk +\n    Age + Sex + Income,\n  data = data_train\n) |&gt;\n  step_impute_median(all_numeric_predictors()) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_dummy(all_nominal_predictors())\n\ndiabetes_rec\nWe also set up 5-fold cross-validation on the training data, stratifying by the outcome, and define a metric set centered on log-loss (here named mn_log_loss in this version of yardstick), with accuracy and ROC AUC for additional context.\n#| label: resamples-and-metrics\n#| message: false\n\nset.seed(2025)\nfolds &lt;- vfold_cv(\n  data_train,\n  v      = 5,\n  strata = Diabetes_binary\n)\n\nlogloss_metrics &lt;- metric_set(mn_log_loss, accuracy, roc_auc)\n\nfolds"
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "Classification Tree",
    "text": "Classification Tree\n\nModel Specification\nWe begin with a classification tree model. The key tuning parameters are:\n\ncost_complexity: controls pruning / tree complexity\n\ntree_depth: maximum depth of the tree\n\nmin_n: minimum number of observations in a terminal node\n\n#| label: tree-spec\n#| message: false\n\ntree_spec &lt;- decision_tree(\n  cost_complexity = tune(),\n  tree_depth      = tune(),\n  min_n           = tune()\n) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\ntree_spec\n\n\nTuning Grid\nWe create a regular grid of hyperparameters to explore a range of tree sizes and complexities.\n#| label: tree-grid\n#| message: false\n\ntree_grid &lt;- grid_regular(\n  cost_complexity(range = c(-4, -1)),\n  tree_depth(range      = c(3, 10)),\n  min_n(range           = c(10, 50)),\n  levels = 3\n)\n\ntree_grid\n\n\nWorkflow and Cross-Validation\nWe combine the recipe and model into a workflow and use 5-fold cross-validation to estimate performance across the grid, focusing on log-loss.\n#| label: tree-tuning\n#| message: false\n#| warning: false\n\ntree_wf &lt;- workflow() |&gt;\n  add_recipe(diabetes_rec) |&gt;\n  add_model(tree_spec)\n\nset.seed(2025)\ntree_res &lt;- tune_grid(\n  tree_wf,\n  resamples = folds,\n  grid      = tree_grid,\n  metrics   = logloss_metrics\n)\n\ntree_res\nWe examine the best-performing tree configurations according to mn_log_loss (lower is better).\n#| label: tree-best\n#| message: false\n\nshow_best(tree_res, metric = \"mn_log_loss\", n = 10)\nWe now select the single best set of hyperparameters and finalize the tree workflow.\n#| label: tree-finalize\n#| message: false\n\nbest_tree &lt;- select_best(tree_res, metric = \"mn_log_loss\")\n\nbest_tree\n\nfinal_tree_wf &lt;- finalize_workflow(tree_wf, best_tree)\n\nfinal_tree_wf\n\n\nFit Final Tree and Evaluate on the Test Set\nWe fit the finalized tree model on the full training data and evaluate its performance on the held-out test set.\n#| label: tree-fit-test\n#| message: false\n#| warning: false\n\nfinal_tree_fit &lt;- final_tree_wf |&gt;\n  fit(data = data_train)\n\ntree_probs &lt;- predict(final_tree_fit, data_test, type = \"prob\") |&gt;\n  bind_cols(data_test |&gt; select(Diabetes_binary))\n\ntree_classes &lt;- predict(final_tree_fit, data_test, type = \"class\") |&gt;\n  bind_cols(data_test |&gt; select(Diabetes_binary))\n\n# --- metrics computed with correct prediction types ---\n\n# log-loss uses probabilities\ntree_logloss &lt;- mn_log_loss(\n  tree_probs,\n  truth   = Diabetes_binary,\n  .pred_Diabetes\n)\n\n# accuracy uses class predictions\ntree_accuracy &lt;- accuracy(\n  tree_classes,\n  truth   = Diabetes_binary,\n  .pred_class\n)\n\n# ROC AUC uses probabilities\ntree_roc &lt;- roc_auc(\n  tree_probs,\n  truth   = Diabetes_binary,\n  .pred_Diabetes\n)\n\ntree_metrics &lt;- bind_rows(tree_logloss, tree_accuracy, tree_roc)\n\ntree_cm &lt;- conf_mat(\n  tree_classes,\n  truth   = Diabetes_binary,\n  estimate = .pred_class\n)\n\ntree_metrics\n\n#| label: tree-conf-matrix\n#| message: false\n\ntree_cm"
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "Random Forest",
    "text": "Random Forest\n\nModel Specification\nWe now consider a random forest model, which fits an ensemble of decision trees and averages their predictions. The main tuning parameters are:\n\nmtry: number of predictors sampled at each split\n\nmin_n: minimum number of observations in a terminal node\n\ntrees: total number of trees in the forest\n\nwe were using 1000 trees but reduced to 10 because of the computational time\n#| label: rf-spec\n#| message: false\n\nrf_spec &lt;- rand_forest(\n  mtry  = tune(),\n  min_n = tune(),\n  trees = 10\n) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"classification\")\n\nrf_spec\n\n\nTuning Grid\nWe set up a grid for mtry and min_n. Because the number of predictors after dummy encoding is not known ahead of time, we estimate a reasonable range for mtry based on the training data.\n#| label: rf-grid\n#| message: false\n\n# approximate number of predictors after dummying\nprep_rec &lt;- diabetes_rec |&gt;\n  prep(training = data_train)\n\ntrain_processed &lt;- bake(prep_rec, new_data = data_train)\n\nn_pred &lt;- ncol(train_processed) - 1  # subtract outcome\n\nn_pred\n\nrf_grid &lt;- grid_regular(\n  mtry(range = c(2, min(10, n_pred))),\n  min_n(range = c(5, 25)),\n  levels = 4\n)\n\nrf_grid\n\n\nWorkflow and Cross-Validation\nWe create a workflow for the random forest model and tune it using the same 5-fold cross-validation folds and log-loss metric.\n#| label: rf-tuning\n#| message: false\n#| warning: false\n\nrf_wf &lt;- workflow() |&gt;\n  add_recipe(diabetes_rec) |&gt;\n  add_model(rf_spec)\n\nset.seed(2025)\nrf_res &lt;- tune_grid(\n  rf_wf,\n  resamples = folds,\n  grid      = rf_grid,\n  metrics   = logloss_metrics\n)\n\nrf_res\nWe examine the best-performing random forest configurations.\n#| label: rf-best\n#| message: false\n\nshow_best(rf_res, metric = \"mn_log_loss\", n = 10)\nWe then select the best tuning parameters and finalize the workflow.\n#| label: rf-finalize\n#| message: false\n\nbest_rf &lt;- select_best(rf_res, metric = \"mn_log_loss\")\n\nbest_rf\n\nfinal_rf_wf &lt;- finalize_workflow(rf_wf, best_rf)\n\nfinal_rf_wf\n\n\nFit Final Random Forest and Evaluate on the Test Set\nWe fit the finalized random forest on the full training data and evaluate it on the test set.\n#| label: rf-fit-test\n#| message: false\n#| warning: false\n\nfinal_rf_fit &lt;- final_rf_wf |&gt;\n  fit(data = data_train)\n\nrf_probs &lt;- predict(final_rf_fit, data_test, type = \"prob\") |&gt;\n  bind_cols(data_test |&gt; select(Diabetes_binary))\n\nrf_classes &lt;- predict(final_rf_fit, data_test, type = \"class\") |&gt;\n  bind_cols(data_test |&gt; select(Diabetes_binary))\n\n# --- metrics with correct prediction types ---\n\n# log-loss uses probabilities\nrf_logloss &lt;- mn_log_loss(\n  rf_probs,\n  truth   = Diabetes_binary,\n  .pred_Diabetes\n)\n\n# accuracy uses class predictions\nrf_accuracy &lt;- accuracy(\n  rf_classes,\n  truth   = Diabetes_binary,\n  .pred_class\n)\n\n# ROC AUC uses probabilities\nrf_roc &lt;- roc_auc(\n  rf_probs,\n  truth   = Diabetes_binary,\n  .pred_Diabetes\n)\n\nrf_metrics &lt;- bind_rows(rf_logloss, rf_accuracy, rf_roc)\n\nrf_cm &lt;- conf_mat(\n  rf_classes,\n  truth    = Diabetes_binary,\n  estimate = .pred_class\n)\n\nrf_metrics\n\n#| label: rf-conf-matrix\n#| message: false\n\nrf_cm"
  },
  {
    "objectID": "Modeling.html#final-model-comparison",
    "href": "Modeling.html#final-model-comparison",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "Final Model Comparison",
    "text": "Final Model Comparison\nWe now compare the test set performance of the tuned classification tree and random forest models. Our primary metric is log-loss (reported here as mn_log_loss, lower is better), but we also consider accuracy and ROC AUC.\n#| label: compare-models\n#| message: false\n\ntree_summary &lt;- tree_metrics |&gt;\n  mutate(model = \"Classification tree\")\n\nrf_summary &lt;- rf_metrics |&gt;\n  mutate(model = \"Random forest\")\n\nbind_rows(tree_summary, rf_summary) |&gt;\n  select(model, .metric, .estimate) |&gt;\n  arrange(.metric, desc(.estimate))\nTypically we expect the random forest to outperform a single tree on log-loss and ROC AUC due to its ensemble nature and better ability to capture complex interactions.reducing the tree parameters for 10 caused the random forest to be slightly worse than the classification tree, so likely this will be our champion model."
  },
  {
    "objectID": "Modeling.html#conclusion",
    "href": "Modeling.html#conclusion",
    "title": "Diabetes Health Indicators – Modeling",
    "section": "Conclusion",
    "text": "Conclusion\nIn this modeling analysis we:\n\nCreated a binary diabetes outcome from the original three-level Diabetes_012 variable.\nSplit the data into stratified training and test sets.\nBuilt a preprocessing recipe that handles missing values and encodes categorical predictors.\nTuned a classification tree model using 5-fold cross-validation and log-loss.\nTuned a random forest model using the same resampling scheme and metrics.\nCompared the tuned tree and random forest on the test set.\n\nBased on the test set results, we select the model with the lowest log-loss (and typically higher ROC AUC) as our final model. This chosen model will be refit on the full dataset and exposed via a plumber API in the next stage of the project."
  }
]