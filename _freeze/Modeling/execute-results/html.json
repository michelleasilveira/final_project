{
  "hash": "9d2ce98c5d3b2e786b6052ebde6da4f3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Diabetes Health Indicators – Modeling\"\nauthor: \"Michelle A Silveira\"\nformat:\n  html:\n    toc: true\n    toc-location: left\n    theme: cosmo\n---\n\n## Introduction\n\nIn this report we build and compare predictive models for diabetes using the **Diabetes Health Indicators** dataset (`diabetes_binary_health_indicators_BRFSS2015`). The original outcome variable, `Diabetes_012`, has three categories:\n\n-   `0` = no diabetes\\\n-   `1` = prediabetes\\\n-   `2` = diabetes\n\nFor this project we follow the course instructions and work with a **binary** response. We define a new variable, `Diabetes_binary`, that indicates whether a respondent has diabetes (`1`) or not (`0`):\n\n-   `Diabetes_binary = 1` if `Diabetes_012 == 2` (diabetes)\\\n-   `Diabetes_binary = 0` otherwise (no diabetes or prediabetes)\n\nOur goals in this document are to:\n\n-   Create a training/test split of the data.\n-   Specify a modeling recipe based on insights from the EDA.\n-   Fit and tune a **classification tree** model.\n-   Fit and tune a **random forest** model.\n-   Use **log-loss** with 5-fold cross-validation to select the best model in each family.\n-   Compare the final tuned models on the test set and select a winner.\n\nWe use the **tidymodels** framework to keep preprocessing, resampling, tuning, and evaluation organized and reproducible.\n\n------------------------------------------------------------------------\n\n## Load Packages\n\nWe begin by loading the packages needed for modeling.\n\n\n\n\n------------------------------------------------------------------------\n\n## Read and Prepare the Data\n\nHere we read the same dataset used in the EDA and perform minimal cleaning so that the modeling file is self-contained. We:\n\n-   Keep a numeric copy of `Diabetes_012`.\n-   Create a **binary** outcome `Diabetes_binary` (No_diabetes vs Diabetes).\n-   Recode `Sex` as a factor with labels.\n-   Provide interpretable labels for `GenHlth` and `Age`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes_raw <- readr::read_csv(\n  \"data/diabetes_binary_health_indicators_BRFSS2015.csv\"\n)\n\nage_labels <- c(\n  \"18–24\", \"25–29\", \"30–34\", \"35–39\",\n  \"40–44\", \"45–49\", \"50–54\", \"55–59\",\n  \"60–64\", \"65–69\", \"70–74\", \"75–79\", \"80+\"\n)\n\ndiabetes <- diabetes_raw |>\n  mutate(\n    Diabetes_num = Diabetes_012,\n    Diabetes_012 = factor(\n      Diabetes_012,\n      levels = c(0, 1, 2),\n      labels = c(\"No_diabetes\", \"Prediabetes\", \"Diabetes\")\n    ),\n    # Binary response for modeling\n    Diabetes_binary = if_else(Diabetes_012 == \"Diabetes\", 1, 0),\n    Diabetes_binary = factor(\n      Diabetes_binary,\n      levels = c(0, 1),\n      labels = c(\"No_diabetes\", \"Diabetes\")\n    ),\n    Sex = factor(\n      Sex,\n      levels = c(0, 1),\n      labels = c(\"Female\", \"Male\")\n    ),\n    GenHlth = factor(\n      GenHlth,\n      levels = 1:5,\n      labels = c(\"Excellent\", \"Very_good\", \"Good\", \"Fair\", \"Poor\"),\n      ordered = TRUE\n    ),\n    Age_num = Age,\n    Age = factor(\n      Age,\n      levels = 1:13,\n      labels = age_labels,\n      ordered = TRUE\n    )\n  )\n\ndiabetes |> \n  count(Diabetes_binary) |> \n  mutate(prop = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  Diabetes_binary      n  prop\n  <fct>            <int> <dbl>\n1 No_diabetes     218334 0.861\n2 Diabetes         35346 0.139\n```\n\n\n:::\n:::\n\n\n*The binary outcome is imbalanced, with the \"Diabetes\" class representing a smaller proportion of observations. This will influence how we interpret log-loss and other metrics.*\n\n------------------------------------------------------------------------\n\n## Train/Test Split\n\nWe now split the data into a training set (70%) and a test set (30%), stratifying on the binary outcome to preserve class proportions in each partition.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2025)\n\ndata_split <- initial_split(\n  diabetes,\n  prop   = 0.7,\n  strata = Diabetes_binary\n)\n\ndata_train <- training(data_split)\ndata_test  <- testing(data_split)\n\nprint(data_split)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<177575/76105/253680>\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Modeling Strategy and Predictors\n\nGuided by the EDA, we choose a set of predictors that showed meaningful associations with diabetes status:\n\n-   `HighBP`, `HighChol`, `BMI`, `Smoker`\\\n-   `PhysActivity`, `GenHlth`, `DiffWalk`\\\n-   `Age`, `Sex`, `Income`\n\nWe build a **recipe** that:\n\n-   Specifies the outcome and predictors.\n-   Handles missing values for numeric predictors via median imputation.\n-   Handles missing values for nominal predictors via mode imputation.\n-   Creates dummy variables for nominal predictors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes_rec <- recipe(\n  Diabetes_binary ~ HighBP + HighChol + BMI + Smoker +\n    PhysActivity + GenHlth + DiffWalk +\n    Age + Sex + Income,\n  data = data_train\n) |>\n  step_impute_median(all_numeric_predictors()) |>\n  step_impute_mode(all_nominal_predictors()) |>\n  step_dummy(all_nominal_predictors())\n\nprint(diabetes_rec)\n```\n:::\n\n\nWe also set up 5-fold cross-validation on the training data, stratifying by the outcome, and define a metric set centered on **log-loss** (here named `mn_log_loss` in this version of yardstick), with accuracy and ROC AUC for additional context.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2025)\nfolds <- vfold_cv(\n  data_train,\n  v      = 5,\n  strata = Diabetes_binary\n)\n\nlogloss_metrics <- metric_set(mn_log_loss, accuracy, roc_auc)\n\nprint(folds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#  5-fold cross-validation using stratification \n# A tibble: 5 × 2\n  splits                 id   \n  <list>                 <chr>\n1 <split [142059/35516]> Fold1\n2 <split [142059/35516]> Fold2\n3 <split [142060/35515]> Fold3\n4 <split [142061/35514]> Fold4\n5 <split [142061/35514]> Fold5\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Classification Tree\n\n### Model Specification\n\nWe begin with a **classification tree** model. The key tuning parameters are:\n\n-   `cost_complexity`: controls pruning / tree complexity\\\n-   `tree_depth`: maximum depth of the tree\\\n-   `min_n`: minimum number of observations in a terminal node\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_spec <- decision_tree(\n  cost_complexity = tune(),\n  tree_depth      = tune(),\n  min_n           = tune()\n) |>\n  set_engine(\"rpart\") |>\n  set_mode(\"classification\")\n\nprint(tree_spec)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n  min_n = tune()\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n\n### Tuning Grid\n\nWe create a regular grid of hyperparameters to explore a range of tree sizes and complexities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_grid <- grid_regular(\n  cost_complexity(range = c(-4, -1)),\n  tree_depth(range      = c(3, 10)),\n  min_n(range           = c(10, 50)),\n  levels = 3\n)\n\nprint(tree_grid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 27 × 3\n   cost_complexity tree_depth min_n\n             <dbl>      <int> <int>\n 1         0.0001           3    10\n 2         0.00316          3    10\n 3         0.1              3    10\n 4         0.0001           6    10\n 5         0.00316          6    10\n 6         0.1              6    10\n 7         0.0001          10    10\n 8         0.00316         10    10\n 9         0.1             10    10\n10         0.0001           3    30\n# ℹ 17 more rows\n```\n\n\n:::\n:::\n\n\n### Workflow and Cross-Validation\n\nWe combine the recipe and model into a workflow and use 5-fold cross-validation to estimate performance across the grid, focusing on log-loss.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_wf <- workflow() |>\n  add_recipe(diabetes_rec) |>\n  add_model(tree_spec)\n\nset.seed(2025)\ntree_res <- tune_grid(\n  tree_wf,\n  resamples = folds,\n  grid      = tree_grid,\n  metrics   = logloss_metrics\n)\n\nprint(tree_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits                 id    .metrics          .notes          \n  <list>                 <chr> <list>            <list>          \n1 <split [142059/35516]> Fold1 <tibble [81 × 7]> <tibble [0 × 4]>\n2 <split [142059/35516]> Fold2 <tibble [81 × 7]> <tibble [0 × 4]>\n3 <split [142060/35515]> Fold3 <tibble [81 × 7]> <tibble [0 × 4]>\n4 <split [142061/35514]> Fold4 <tibble [81 × 7]> <tibble [0 × 4]>\n5 <split [142061/35514]> Fold5 <tibble [81 × 7]> <tibble [0 × 4]>\n```\n\n\n:::\n:::\n\n\nWe examine the best-performing tree configurations according to **mn_log_loss** (lower is better).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(tree_res, metric = \"mn_log_loss\", n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 9\n   cost_complexity tree_depth min_n .metric     .estimator  mean     n std_err\n             <dbl>      <int> <int> <chr>       <chr>      <dbl> <int>   <dbl>\n 1         0.0001          10    50 mn_log_loss binary     0.343     5 0.00299\n 2         0.0001          10    30 mn_log_loss binary     0.343     5 0.00301\n 3         0.0001          10    10 mn_log_loss binary     0.346     5 0.00249\n 4         0.0001           6    10 mn_log_loss binary     0.356     5 0.00137\n 5         0.0001           6    30 mn_log_loss binary     0.356     5 0.00137\n 6         0.0001           6    50 mn_log_loss binary     0.356     5 0.00137\n 7         0.00316          6    10 mn_log_loss binary     0.356     5 0.00137\n 8         0.00316          6    30 mn_log_loss binary     0.356     5 0.00137\n 9         0.00316          6    50 mn_log_loss binary     0.356     5 0.00137\n10         0.00316         10    10 mn_log_loss binary     0.356     5 0.00137\n# ℹ 1 more variable: .config <chr>\n```\n\n\n:::\n:::\n\n\nWe now select the single best set of hyperparameters and finalize the tree workflow.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_tree <- select_best(tree_res, metric = \"mn_log_loss\")\n\nprint(best_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  cost_complexity tree_depth min_n .config         \n            <dbl>      <int> <int> <chr>           \n1          0.0001         10    50 pre0_mod09_post0\n```\n\n\n:::\n\n```{.r .cell-code}\nfinal_tree_wf <- finalize_workflow(tree_wf, best_tree)\n\nprint(final_tree_wf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_impute_median()\n• step_impute_mode()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-04\n  tree_depth = 10\n  min_n = 50\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n\n### Fit Final Tree and Evaluate on the Test Set\n\nWe fit the finalized tree model on the full training data and evaluate its performance on the held-out test set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_tree_fit <- final_tree_wf |>\n  fit(data = data_train)\n\ntree_probs <- predict(final_tree_fit, data_test, type = \"prob\") |>\n  bind_cols(data_test |> select(Diabetes_binary))\n\ntree_classes <- predict(final_tree_fit, data_test, type = \"class\") |>\n  bind_cols(data_test |> select(Diabetes_binary))\n\n# --- metrics computed with correct prediction types ---\n\n# log-loss uses probabilities\ntree_logloss <- mn_log_loss(\n  tree_probs,\n  truth   = Diabetes_binary,\n  .pred_Diabetes\n)\n\n# accuracy uses class predictions\ntree_accuracy <- accuracy(\n  tree_classes,\n  truth   = Diabetes_binary,\n  .pred_class\n)\n\n# ROC AUC uses probabilities\ntree_roc <- roc_auc(\n  tree_probs,\n  truth   = Diabetes_binary,\n  .pred_Diabetes\n)\n\ntree_metrics <- bind_rows(tree_logloss, tree_accuracy, tree_roc)\n\ntree_cm <- conf_mat(\n  tree_classes,\n  truth   = Diabetes_binary,\n  estimate = .pred_class\n)\n\nprint(tree_metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 mn_log_loss binary         2.10 \n2 accuracy    binary         0.866\n3 roc_auc     binary         0.250\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(tree_cm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Truth\nPrediction    No_diabetes Diabetes\n  No_diabetes       64446     9165\n  Diabetes           1055     1439\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Random Forest\n\n### Model Specification\n\nWe now consider a **random forest** model, which fits an ensemble of decision trees and averages their predictions. The main tuning parameters are:\n\n-   `mtry`: number of predictors sampled at each split\\\n-   `min_n`: minimum number of observations in a terminal node\\\n-   `trees`: total number of trees in the forest\n\nwe were using 1000 trees but reduced to 10 because of the computational time\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_spec <- rand_forest(\n  mtry  = tune(),\n  min_n = tune(),\n  trees = 10\n) |>\n  set_engine(\"ranger\", importance = \"impurity\") |>\n  set_mode(\"classification\")\n\nprint(rf_spec)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = impurity\n\nComputational engine: ranger \n```\n\n\n:::\n:::\n\n\n### Tuning Grid\n\nWe set up a grid for `mtry` and `min_n`. Because the number of predictors after dummy encoding is not known ahead of time, we estimate a reasonable range for `mtry` based on the training data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# approximate number of predictors after dummying\nprep_rec <- diabetes_rec |>\n  prep(training = data_train)\n\ntrain_processed <- bake(prep_rec, new_data = data_train)\n\nn_pred <- ncol(train_processed) - 1  # subtract outcome\n\nprint(n_pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 24\n```\n\n\n:::\n\n```{.r .cell-code}\nrf_grid <- grid_regular(\n  mtry(range = c(2, min(10, n_pred))),\n  min_n(range = c(5, 25)),\n  levels = 4\n)\n\nprint(rf_grid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 16 × 2\n    mtry min_n\n   <int> <int>\n 1     2     5\n 2     4     5\n 3     7     5\n 4    10     5\n 5     2    11\n 6     4    11\n 7     7    11\n 8    10    11\n 9     2    18\n10     4    18\n11     7    18\n12    10    18\n13     2    25\n14     4    25\n15     7    25\n16    10    25\n```\n\n\n:::\n:::\n\n\n### Workflow and Cross-Validation\n\nWe create a workflow for the random forest model and tune it using the same 5-fold cross-validation folds and log-loss metric.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_wf <- workflow() |>\n  add_recipe(diabetes_rec) |>\n  add_model(rf_spec)\n\nset.seed(2025)\nrf_res <- tune_grid(\n  rf_wf,\n  resamples = folds,\n  grid      = rf_grid,\n  metrics   = logloss_metrics\n)\n\nprint(rf_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits                 id    .metrics          .notes          \n  <list>                 <chr> <list>            <list>          \n1 <split [142059/35516]> Fold1 <tibble [48 × 6]> <tibble [0 × 4]>\n2 <split [142059/35516]> Fold2 <tibble [48 × 6]> <tibble [0 × 4]>\n3 <split [142060/35515]> Fold3 <tibble [48 × 6]> <tibble [0 × 4]>\n4 <split [142061/35514]> Fold4 <tibble [48 × 6]> <tibble [0 × 4]>\n5 <split [142061/35514]> Fold5 <tibble [48 × 6]> <tibble [0 × 4]>\n```\n\n\n:::\n:::\n\n\nWe examine the best-performing random forest configurations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(rf_res, metric = \"mn_log_loss\", n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 8\n    mtry min_n .metric     .estimator  mean     n  std_err .config         \n   <int> <int> <chr>       <chr>      <dbl> <int>    <dbl> <chr>           \n 1     4    25 mn_log_loss binary     0.323     5 0.000760 pre0_mod08_post0\n 2     4    18 mn_log_loss binary     0.324     5 0.000546 pre0_mod07_post0\n 3     4    11 mn_log_loss binary     0.324     5 0.000631 pre0_mod06_post0\n 4     2    25 mn_log_loss binary     0.324     5 0.000613 pre0_mod04_post0\n 5     2     5 mn_log_loss binary     0.324     5 0.000579 pre0_mod01_post0\n 6     2    18 mn_log_loss binary     0.324     5 0.000766 pre0_mod03_post0\n 7     2    11 mn_log_loss binary     0.325     5 0.000688 pre0_mod02_post0\n 8     4     5 mn_log_loss binary     0.327     5 0.000876 pre0_mod05_post0\n 9     7    25 mn_log_loss binary     0.336     5 0.00183  pre0_mod12_post0\n10     7    18 mn_log_loss binary     0.341     5 0.00185  pre0_mod11_post0\n```\n\n\n:::\n:::\n\n\nWe then select the best tuning parameters and finalize the workflow.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_rf <- select_best(rf_res, metric = \"mn_log_loss\")\n\nprint(best_rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n   mtry min_n .config         \n  <int> <int> <chr>           \n1     4    25 pre0_mod08_post0\n```\n\n\n:::\n\n```{.r .cell-code}\nfinal_rf_wf <- finalize_workflow(rf_wf, best_rf)\n\nprint(final_rf_wf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_impute_median()\n• step_impute_mode()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 4\n  trees = 10\n  min_n = 25\n\nEngine-Specific Arguments:\n  importance = impurity\n\nComputational engine: ranger \n```\n\n\n:::\n:::\n\n\n### Fit Final Random Forest and Evaluate on the Test Set\n\nWe fit the finalized random forest on the full training data and evaluate it on the test set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_rf_fit <- final_rf_wf |>\n  fit(data = data_train)\n\nrf_probs <- predict(final_rf_fit, data_test, type = \"prob\") |>\n  bind_cols(data_test |> select(Diabetes_binary))\n\nrf_classes <- predict(final_rf_fit, data_test, type = \"class\") |>\n  bind_cols(data_test |> select(Diabetes_binary))\n\n# --- metrics with correct prediction types ---\n\n# log-loss uses probabilities\nrf_logloss <- mn_log_loss(\n  rf_probs,\n  truth   = Diabetes_binary,\n  .pred_Diabetes\n)\n\n# accuracy uses class predictions\nrf_accuracy <- accuracy(\n  rf_classes,\n  truth   = Diabetes_binary,\n  .pred_class\n)\n\n# ROC AUC uses probabilities\nrf_roc <- roc_auc(\n  rf_probs,\n  truth   = Diabetes_binary,\n  .pred_Diabetes\n)\n\nrf_metrics <- bind_rows(rf_logloss, rf_accuracy, rf_roc)\n\nrf_cm <- conf_mat(\n  rf_classes,\n  truth    = Diabetes_binary,\n  estimate = .pred_class\n)\n\nprint(rf_metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 mn_log_loss binary         2.75 \n2 accuracy    binary         0.865\n3 roc_auc     binary         0.181\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(rf_cm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Truth\nPrediction    No_diabetes Diabetes\n  No_diabetes       64627     9398\n  Diabetes            874     1206\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Final Model Comparison\n\nWe now compare the **test set performance** of the tuned classification tree and random forest models. Our primary metric is **log-loss** (reported here as `mn_log_loss`, lower is better), but we also consider accuracy and ROC AUC.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_summary <- tree_metrics |>\n  mutate(model = \"Classification tree\")\n\nrf_summary <- rf_metrics |>\n  mutate(model = \"Random forest\")\n\ncomparison <- bind_rows(tree_summary, rf_summary) |>\n  select(model, .metric, .estimate) |>\n  arrange(.metric, desc(.estimate))\n\nprint(comparison)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  model               .metric     .estimate\n  <chr>               <chr>           <dbl>\n1 Classification tree accuracy        0.866\n2 Random forest       accuracy        0.865\n3 Random forest       mn_log_loss     2.75 \n4 Classification tree mn_log_loss     2.10 \n5 Classification tree roc_auc         0.250\n6 Random forest       roc_auc         0.181\n```\n\n\n:::\n:::\n\n\n*Typically we expect the random forest to outperform a single tree on log-loss and ROC AUC due to its ensemble nature and better ability to capture complex interactions. However reducing the tree parameters in the random forest model = 10 caused the random forest to be slightly worse than the classification tree, so likely this will be our champion model.*\n\n------------------------------------------------------------------------\n\n## Conclusion\n\nIn this modeling analysis we:\n\n-   Created a binary diabetes outcome from the original three-level `Diabetes_012` variable.\n-   Split the data into stratified training and test sets.\n-   Built a preprocessing recipe that handles missing values and encodes categorical predictors.\n-   Tuned a classification tree model using 5-fold cross-validation and log-loss.\n-   Tuned a random forest model using the same resampling scheme and metrics.\n-   Compared the tuned tree and random forest on the test set.\n\nBased on the test set results, we select the model with the **lowest log-loss** (and typically higher ROC AUC) as our final model. This chosen/champion model will be refit on the full dataset and exposed via a **plumber API** in the next stage of the project.\n\n## Saving champion model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make sure the 'model' directory exists\nif (!dir.exists(\"model\")) dir.create(\"model\")\n\n# Print champion model (optional)\nprint(final_tree_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_impute_median()\n• step_impute_mode()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 177575 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 177575 24742 No_diabetes (0.86066732 0.13933268)  \n     2) HighBP< 0.5 101438  6160 No_diabetes (0.93927325 0.06072675) *\n     3) HighBP>=0.5 76137 18582 No_diabetes (0.75593995 0.24406005)  \n       6) GenHlth_1< 0.1581139 55922 10469 No_diabetes (0.81279282 0.18720718)  \n        12) GenHlth_1< -0.1581139 28633  3525 No_diabetes (0.87689030 0.12310970)  \n          24) BMI< 32.5 23381  2415 No_diabetes (0.89671100 0.10328900) *\n          25) BMI>=32.5 5252  1110 No_diabetes (0.78865194 0.21134806)  \n            50) HighChol< 0.5 2644   389 No_diabetes (0.85287443 0.14712557) *\n            51) HighChol>=0.5 2608   721 No_diabetes (0.72354294 0.27645706)  \n             102) DiffWalk< 0.5 2180   550 No_diabetes (0.74770642 0.25229358) *\n             103) DiffWalk>=0.5 428   171 No_diabetes (0.60046729 0.39953271)  \n               206) Sex_Male< 0.5 275    96 No_diabetes (0.65090909 0.34909091)  \n                 412) Income>=3.5 212    65 No_diabetes (0.69339623 0.30660377) *\n                 413) Income< 3.5 63    31 No_diabetes (0.50793651 0.49206349)  \n                   826) PhysActivity>=0.5 33    12 No_diabetes (0.63636364 0.36363636) *\n                   827) PhysActivity< 0.5 30    11 Diabetes (0.36666667 0.63333333) *\n               207) Sex_Male>=0.5 153    75 No_diabetes (0.50980392 0.49019608)  \n                 414) Age_10>=0.06757444 70    25 No_diabetes (0.64285714 0.35714286) *\n                 415) Age_10< 0.06757444 83    33 Diabetes (0.39759036 0.60240964) *\n        13) GenHlth_1>=-0.1581139 27289  6944 No_diabetes (0.74553850 0.25446150)  \n          26) BMI< 31.5 17264  3577 No_diabetes (0.79280584 0.20719416) *\n          27) BMI>=31.5 10025  3367 No_diabetes (0.66413965 0.33586035)  \n            54) Age_01< 0.1111874 4482  1109 No_diabetes (0.75256582 0.24743418)  \n             108) HighChol< 0.5 2125   345 No_diabetes (0.83764706 0.16235294) *\n             109) HighChol>=0.5 2357   764 No_diabetes (0.67585914 0.32414086)  \n               218) DiffWalk< 0.5 1886   562 No_diabetes (0.70201485 0.29798515) *\n               219) DiffWalk>=0.5 471   202 No_diabetes (0.57112527 0.42887473)  \n                 438) BMI< 33.5 107    34 No_diabetes (0.68224299 0.31775701) *\n                 439) BMI>=33.5 364   168 No_diabetes (0.53846154 0.46153846)  \n                   878) Age_12>=-0.3077051 141    56 No_diabetes (0.60283688 0.39716312)  \n                    1756) BMI< 42.5 87    27 No_diabetes (0.68965517 0.31034483) *\n                    1757) BMI>=42.5 54    25 Diabetes (0.46296296 0.53703704) *\n                   879) Age_12< -0.3077051 223   111 Diabetes (0.49775785 0.50224215)  \n                    1758) Sex_Male< 0.5 150    69 No_diabetes (0.54000000 0.46000000) *\n                    1759) Sex_Male>=0.5 73    30 Diabetes (0.41095890 0.58904110) *\n            55) Age_01>=0.1111874 5543  2258 No_diabetes (0.59263936 0.40736064)  \n             110) HighChol< 0.5 1928   647 No_diabetes (0.66441909 0.33558091)  \n               220) Sex_Male< 0.5 1091   336 No_diabetes (0.69202566 0.30797434) *\n               221) Sex_Male>=0.5 837   311 No_diabetes (0.62843489 0.37156511)  \n                 442) BMI< 39.5 690   239 No_diabetes (0.65362319 0.34637681) *\n                 443) BMI>=39.5 147    72 No_diabetes (0.51020408 0.48979592)  \n                   886) Income>=3.5 123    56 No_diabetes (0.54471545 0.45528455)  \n                    1772) Age_06< 0.1845419 79    31 No_diabetes (0.60759494 0.39240506) *\n                    1773) Age_06>=0.1845419 44    19 Diabetes (0.43181818 0.56818182) *\n                   887) Income< 3.5 24     8 Diabetes (0.33333333 0.66666667) *\n\n...\nand 96 more lines.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Save final fitted tree workflow and the recipe\nsaveRDS(final_tree_fit, \"model/final_tree_fit.rds\")\nsaveRDS(diabetes_rec, \"model/recipe.rds\")\n\nmessage(\"Champion model saved successfully!\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}